{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torch"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iP1yOoVdRifZ",
    "outputId": "9663cd84-072d-4b2c-f942-331209538f59"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2eSvM9zX_2d3"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2v_X2fA0Df5"
   },
   "source": [
    "* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n",
    "* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n",
    "* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n",
    "* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n",
    "* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n",
    "* [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316,
     "referenced_widgets": [
      "7baa5b4300b34ceab088d8039b10082e",
      "b04f98b89e6f4e50bf1f7ad3083ef69c",
      "1d28dd2622b34c0bb07219bc2ba21eee",
      "6b8c9d0956c94475b3bca24dc8d11cf3",
      "4f5c4c8c87cf4db3a3e3381ecb4256dc",
      "3c8131569f7a4282b409d30095e096bc",
      "8052eb3598544fe5a654ed2efeca5032",
      "44953a63ac0d462a8486117fa25267e9",
      "da67bc6cdb9a4621a0b8b17eb8633c6d",
      "bca876d55e514083ad9d5a0969179207",
      "ee3822333a97478896dee3def09ec25a",
      "d869fc5fe6e94152acd5e8dda1213641",
      "02c1e299b8714e359d3dc67865f49a4a",
      "5de307853a9d4a808e078ec4ffdf3e59",
      "b45a9005963a457b8a95fb6e40561724",
      "181ee9324b964dd68ec2fecc553dd70f",
      "aee27f681c81401da3bcb1f7954e871e",
      "e376f93e144f4fe88914c7c8026ba592",
      "02fafecd45ec46bda44737a273761ac8",
      "863a8c27e31d44dda575d7ad5e23ca94",
      "4e7e1c4c6d5948ef9249baf6df90db0d",
      "929df78fd39e4c49ad7e4f7d5b10b747",
      "3be9e1f170cf4ce783015f8669cf45b4",
      "accf6553dff44a9c92b5a92642d3e373",
      "fc4a7167ede041cf993621948c0efbdf",
      "bbad30ef601f47eead2d8ebe08d8cd8c",
      "9972f4f58f2243729014c378a1992530",
      "837aa6977d824a67a17ad5233d2ebc24",
      "41c1f6b385d648cf8043cd23f1c9e481",
      "54f7ddb53c9e41a0887a276bbcf674fa",
      "7c1345fa653b4cc3acf50c45bb2a6bcb",
      "f53b6f9c2de545bcbd5a65444d0d14a4",
      "2d39b88b68c349d6988d9d9db8c4fdc3",
      "2ac67eaf13b1481fae016e0a2f55fb3a",
      "726414f1a1df471b805c5a3d521ae97f",
      "42c290caa90f417d967f0a9d23408477",
      "1717b94845f84bc5adcba1c15f17701e",
      "20740c73df1c47ffb33a6513ad0d8c63",
      "4e7cddfc704446d0be845270ff6b1e56",
      "5bc155cdc6d84607958d18893d0f3eb5",
      "a59737c4bd774e289749757c9897cfb8",
      "b3e9fd6b205740cab8550fb108d8cf0f",
      "d7074ec11ba54890bbca5538eab6e471",
      "a9ea51a30d9a4ae1899679dd2295f57d",
      "d8fee532b11548d999ab04cc1bfdd5eb",
      "14a97002d48948f99e9e00da6e0e95bb",
      "e3a3bfcc094d4c27ac10bbe50b260746",
      "380fe5866222454784777de1647b550e",
      "ea6e3a0af1e046b8a4d4dbcca2fe05b7",
      "cc2b31e91a044d07a412f6380b132a23",
      "3ce4622c77df42dabef093328f035cb9",
      "edd0748b971b4ea98ac7da6a360c2313",
      "7d060e9f48d549d9b69555d16c974018",
      "2357e93f7ea5420294a20a053545a6a5",
      "92ad17d364764a9f894cedd197f7cf7f"
     ]
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "98c2be3a-0907-475b-e5fa-05729e551af3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.10.7: Fast Llama patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7baa5b4300b34ceab088d8039b10082e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/235 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d869fc5fe6e94152acd5e8dda1213641"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3be9e1f170cf4ce783015f8669cf45b4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ac67eaf13b1481fae016e0a2f55fb3a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8fee532b11548d999ab04cc1bfdd5eb"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6bZsfBuZDeCL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6d84d5cd-f04e-46c6-fcbe-01082e6bf176"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth 2025.10.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install datasets"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3x_vdLsXVtDP",
    "outputId": "91f451de-0c98-4458-9f1d-df86c0c94bcd"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('yuan-yang/MALLS-v0')\n",
    "print(dataset.column_names)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "650b79173839420594c8befc6869cbee",
      "f35a4b6ae8fb419a87b2a6729fddc3c1",
      "81ec1230e0824d3dafeb7bb06a75cb90",
      "3f7a524289f04a398aad026d6d3f8bf9",
      "ca0c953f030b4f908bb610445fb54330",
      "7924f29c0fbf4955912c47ed52ea5846",
      "f414524f96c346e6bf73b5955e646453",
      "0005eb8cf03340a2a42a215563cef428",
      "1fe53a99668544c197f7ebc2da4ebe19",
      "aa582a7f39a14cfa85c0b42b5d066de0",
      "b82c2cc68e8344f8acfd39f9c4443874",
      "526bdba246bd48688dfdd19a248008ce",
      "3f93addd2e4d4af698d347345b32db2b",
      "9548014ab76e463eb274219ef7c44867",
      "ca45d350c04e47bd8a8692b98d9b8cc5",
      "825ce3315ad84d019f05febf5808827a",
      "52da0ade7ee54942853b362ee6524b50",
      "6bed0998f37f48d48fc2eb402a7210c4",
      "c4c9e1edf2fe454187eedc5432b0e51e",
      "41b84193ef46435c9740e3ef52674e37",
      "e7f4c4329c3942ba9e2cf70ff91e5971",
      "a72944634a144cf59bf23e9800dddda5",
      "f53521aee03c4ccc998eee185bb19fef",
      "e6c1496944304773967c2b9dd6111f09",
      "7b822420ed2141eab55e38329c9736f1",
      "8334fca4f53346c1b03dfa9fc382dabd",
      "502e953aa02c45be9b9a211a5cdaaafa",
      "405badee8d4f454a865e78d2e9e56a2a",
      "92422d0f5aa846c99ee731d542acfa36",
      "42362eea1f3948f8a969c2a3638fbd46",
      "3fe4fa61943d424da9a1f556ed10d643",
      "889cab33e21c404dbb0d27af2461e3c0",
      "bf28272d22ee4db18c471ed4c7a1cf03",
      "95fe1fa7705c45838cb0952b2f387705",
      "51a1e611bb5549acbc10ada1eb05ea9e",
      "a089c3bb5a3d491ca8c8c02853c9eed8",
      "bc0665e59c5c42c6af8a0f00af09aafa",
      "c893cfdab22f4884945aa6f52b402710",
      "d9752234cb44435b95ba50614c9071db",
      "13a815ff349e43c8af43b1b29dc3d6c4",
      "b99ec316b91b4b29a96744d37e992342",
      "13d8b86e8dde4ee1b67e838c47116bf8",
      "50883e4471b04c4a9a564d8981dacbdd",
      "7a01a715cc6d4d96931dd6f12749cffb",
      "8afa188e0c6945c097a6832d194c9769",
      "c5f949e86a3749aca1bc03ffca646673",
      "37070ed0c58a47a0b640d843584e525d",
      "362aee1f29ba48d695be4af0066617ff",
      "ecadbf57deb54b4d8deb0c982c986639",
      "151a776bb5fb48ab8fb72df69a7ed152",
      "b96c8b83cd1245adbf591d2206bf08cd",
      "045175e8c51a4e86863f86d3d7b567b3",
      "1f3accbe3f9c44ddb47efcc559be1c11",
      "5e03a5b7493049ff88f8272ac845e505",
      "8dc064f9373046cebbc3b3759145b848"
     ]
    },
    "id": "RiGHW_lGUsTu",
    "outputId": "01400bc8-75af-432e-f07b-c4229ab83364"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "650b79173839420594c8befc6869cbee"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "MALLS-v0.1-train.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "526bdba246bd48688dfdd19a248008ce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "MALLS-v0.1-test.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f53521aee03c4ccc998eee185bb19fef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/27284 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95fe1fa7705c45838cb0952b2f387705"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8afa188e0c6945c097a6832d194c9769"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'train': ['FOL', 'NL'], 'test': ['FOL', 'NL']}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "malls_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    # Create a static instruction for all examples.\n",
    "    instruction_text = \"Translate the following natural language statements into their corresponding first-order logic representations.\"\n",
    "    nls = examples[\"NL\"]\n",
    "    fols  = examples[\"FOL\"]\n",
    "    texts = []\n",
    "\n",
    "    for fol, nl in zip(fols, nls):\n",
    "        text = malls_prompt.format(instruction_text, nl, fol) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "\n",
    "    # Tokenize the formatted text\n",
    "    tokenized_output = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=512)  # Adjust max_length as needed\n",
    "    return tokenized_output\n",
    "\n",
    "# Apply formatting and tokenization\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# Check dataset structure\n",
    "print(dataset[\"train\"].column_names)\n",
    "# Check dataset structure\n",
    "print(dataset[\"test\"].column_names)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "a0e0f23821bc45dab973764e04697038",
      "92d0d2b8dd364504aed17760e270cfda",
      "f0f2d989b0a6479b80b5d8c9f372d57c",
      "6cf1ef325f1f4b9e9cf4f0d8a4a12c74",
      "932b9922f5c649cbac4122981b73d7d4",
      "4a36bf1d8b124152bb795d47bc3a4998",
      "951480d660bb4011a3a470dc2f970796",
      "1f623a64c70346b988df8770b7cb6fa5",
      "4df2f53066334853a45a4eb5b45ac3ed",
      "79986a74228d40d7a33e71ca4e9ca4c5",
      "fa96f54d85394531bf3be56d6b9521cc",
      "e1fc45814a5147dd9bea302ebc2449c6",
      "27a6bab850f94138be2f3ff883bcb5b6",
      "807f10530e7643de88e65a11a5286f2d",
      "6bd85ba0decb464fabeb4dfa933bf1b2",
      "6f110e775df049568a4b07cb02bd6776",
      "41aa58f2ed514ffda4f5a918e884681b",
      "2253edf221434a09abe70b1d9f9573d0",
      "7f50760b40284705996c0a92b08dcdfe",
      "faa8da1dbd00451193bf8211ee969b6b",
      "7ff71ac645df48cd9d6b8c1d605c6b76",
      "04babbae0dc740148f7abb76970924f8"
     ]
    },
    "id": "Pk6KXOcnffDt",
    "outputId": "666735fa-0fe4-453a-d03b-f38294df1913"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/27284 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0e0f23821bc45dab973764e04697038"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1fc45814a5147dd9bea302ebc2449c6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['FOL', 'NL', 'input_ids', 'attention_mask']\n",
      "['FOL', 'NL', 'input_ids', 'attention_mask']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "95_Nn-89DhsL"
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 45,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2ejIt2xSNKKp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e76746e8-40de-4ab0-a672-52adec460277"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU = Tesla T4. Max memory = 14.741 GB.\n",
      "6.971 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yqxqAZ7KJ4oL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "e4be71c8-30b0-4be0-a56e-6481740c4727"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 27,284 | Num Epochs = 1 | Total steps = 45\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 07:49, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.819600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.866100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9.279100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7.655800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.584500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6.418900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.321900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.343600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>4.991200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>4.871100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>4.885800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>4.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>4.819500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>4.905800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.826800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>4.845700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>4.927800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>4.886900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>4.804800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>4.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>4.834100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>4.824500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>4.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>4.872300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.844000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>4.831700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>4.836700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>4.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>4.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>4.921300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset['test'].column_names"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNZM6XPdB47L",
    "outputId": "28a70844-fe80-4db9-caf4-2f531d3a2fed"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['FOL', 'NL', 'input_ids', 'attention_mask']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Access the log history (a list of dictionaries) from the Trainer's state\n",
    "log_history = trainer.state.log_history\n",
    "print(log_history)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXYn1qk6NlRR",
    "outputId": "ac830193-c223-40d5-b37e-3a0b15f6f96f"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'loss': 9.8196, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 0.00029321213898255387, 'step': 1}, {'loss': 9.8923, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 0.0005864242779651077, 'step': 2}, {'loss': 9.8661, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 0.0008796364169476617, 'step': 3}, {'loss': 9.7041, 'grad_norm': 27.694047927856445, 'learning_rate': 0.0, 'epoch': 0.0011728485559302155, 'step': 4}, {'loss': 9.8018, 'grad_norm': 29.6751766204834, 'learning_rate': 4e-05, 'epoch': 0.0014660606949127694, 'step': 5}, {'loss': 9.3467, 'grad_norm': nan, 'learning_rate': 8e-05, 'epoch': 0.0017592728338953233, 'step': 6}, {'loss': 9.2791, 'grad_norm': 24.587417602539062, 'learning_rate': 8e-05, 'epoch': 0.002052484972877877, 'step': 7}, {'loss': 8.1, 'grad_norm': 6.153500556945801, 'learning_rate': 0.00012, 'epoch': 0.002345697111860431, 'step': 8}, {'loss': 7.6558, 'grad_norm': 5.480885982513428, 'learning_rate': 0.00016, 'epoch': 0.002638909250842985, 'step': 9}, {'loss': 6.9757, 'grad_norm': 3.958873748779297, 'learning_rate': 0.0002, 'epoch': 0.002932121389825539, 'step': 10}, {'loss': 6.5845, 'grad_norm': 3.9026031494140625, 'learning_rate': 0.000195, 'epoch': 0.0032253335288080927, 'step': 11}, {'loss': 6.4189, 'grad_norm': 2.6544790267944336, 'learning_rate': 0.00019, 'epoch': 0.0035185456677906467, 'step': 12}, {'loss': 6.0962, 'grad_norm': 1.8337570428848267, 'learning_rate': 0.00018500000000000002, 'epoch': 0.0038117578067732006, 'step': 13}, {'loss': 6.0182, 'grad_norm': 8.858107566833496, 'learning_rate': 0.00018, 'epoch': 0.004104969945755754, 'step': 14}, {'loss': 5.6331, 'grad_norm': 1.7093958854675293, 'learning_rate': 0.000175, 'epoch': 0.004398182084738308, 'step': 15}, {'loss': 5.528, 'grad_norm': 1.4133611917495728, 'learning_rate': 0.00017, 'epoch': 0.004691394223720862, 'step': 16}, {'loss': 5.3219, 'grad_norm': 0.9783850908279419, 'learning_rate': 0.000165, 'epoch': 0.004984606362703416, 'step': 17}, {'loss': 5.4286, 'grad_norm': 0.7540327906608582, 'learning_rate': 0.00016, 'epoch': 0.00527781850168597, 'step': 18}, {'loss': 5.3436, 'grad_norm': 0.9209060668945312, 'learning_rate': 0.000155, 'epoch': 0.005571030640668524, 'step': 19}, {'loss': 5.2261, 'grad_norm': 0.7113250494003296, 'learning_rate': 0.00015000000000000001, 'epoch': 0.005864242779651078, 'step': 20}, {'loss': 4.9912, 'grad_norm': 0.472080260515213, 'learning_rate': 0.000145, 'epoch': 0.0061574549186336315, 'step': 21}, {'loss': 5.1383, 'grad_norm': 0.5170530080795288, 'learning_rate': 0.00014, 'epoch': 0.0064506670576161855, 'step': 22}, {'loss': 5.0495, 'grad_norm': 0.6360779404640198, 'learning_rate': 0.00013500000000000003, 'epoch': 0.006743879196598739, 'step': 23}, {'loss': 4.8711, 'grad_norm': 0.33001697063446045, 'learning_rate': 0.00013000000000000002, 'epoch': 0.007037091335581293, 'step': 24}, {'loss': 5.0537, 'grad_norm': 0.34199485182762146, 'learning_rate': 0.000125, 'epoch': 0.007330303474563847, 'step': 25}, {'loss': 4.8858, 'grad_norm': 0.34635308384895325, 'learning_rate': 0.00012, 'epoch': 0.007623515613546401, 'step': 26}, {'loss': 4.9225, 'grad_norm': 0.30167117714881897, 'learning_rate': 0.00011499999999999999, 'epoch': 0.007916727752528954, 'step': 27}, {'loss': 4.8195, 'grad_norm': 0.29216936230659485, 'learning_rate': 0.00011000000000000002, 'epoch': 0.008209939891511508, 'step': 28}, {'loss': 4.9058, 'grad_norm': 1.1274583339691162, 'learning_rate': 0.000105, 'epoch': 0.008503152030494062, 'step': 29}, {'loss': 4.8268, 'grad_norm': 0.21634937822818756, 'learning_rate': 0.0001, 'epoch': 0.008796364169476616, 'step': 30}, {'loss': 4.8457, 'grad_norm': 0.8223623037338257, 'learning_rate': 9.5e-05, 'epoch': 0.00908957630845917, 'step': 31}, {'loss': 4.9278, 'grad_norm': 0.2045750617980957, 'learning_rate': 9e-05, 'epoch': 0.009382788447441724, 'step': 32}, {'loss': 4.8869, 'grad_norm': 0.18497025966644287, 'learning_rate': 8.5e-05, 'epoch': 0.009676000586424278, 'step': 33}, {'loss': 4.8048, 'grad_norm': 0.1804485023021698, 'learning_rate': 8e-05, 'epoch': 0.009969212725406832, 'step': 34}, {'loss': 4.8621, 'grad_norm': 0.17880553007125854, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.010262424864389386, 'step': 35}, {'loss': 4.8341, 'grad_norm': 0.18467605113983154, 'learning_rate': 7e-05, 'epoch': 0.01055563700337194, 'step': 36}, {'loss': 4.8245, 'grad_norm': 0.18896131217479706, 'learning_rate': 6.500000000000001e-05, 'epoch': 0.010848849142354493, 'step': 37}, {'loss': 4.7397, 'grad_norm': 0.20868036150932312, 'learning_rate': 6e-05, 'epoch': 0.011142061281337047, 'step': 38}, {'loss': 4.8723, 'grad_norm': 0.20369920134544373, 'learning_rate': 5.500000000000001e-05, 'epoch': 0.011435273420319601, 'step': 39}, {'loss': 4.844, 'grad_norm': 0.1754394918680191, 'learning_rate': 5e-05, 'epoch': 0.011728485559302155, 'step': 40}, {'loss': 4.8317, 'grad_norm': 0.20055073499679565, 'learning_rate': 4.5e-05, 'epoch': 0.01202169769828471, 'step': 41}, {'loss': 4.8367, 'grad_norm': 0.18508075177669525, 'learning_rate': 4e-05, 'epoch': 0.012314909837267263, 'step': 42}, {'loss': 4.9041, 'grad_norm': 0.16388554871082306, 'learning_rate': 3.5e-05, 'epoch': 0.012608121976249817, 'step': 43}, {'loss': 4.9088, 'grad_norm': 0.15149487555027008, 'learning_rate': 3e-05, 'epoch': 0.012901334115232371, 'step': 44}, {'loss': 4.9213, 'grad_norm': 0.16737043857574463, 'learning_rate': 2.5e-05, 'epoch': 0.013194546254214925, 'step': 45}, {'train_runtime': 492.2389, 'train_samples_per_second': 0.731, 'train_steps_per_second': 0.091, 'total_flos': 8346231940055040.0, 'train_loss': 6.007757186889648, 'epoch': 0.013194546254214925, 'step': 45}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Convert log history to a DataFrame\n",
    "df = pd.DataFrame(log_history)\n",
    "\n",
    "# Check if the necessary columns exist\n",
    "if 'loss' in df.columns and 'step' in df.columns:\n",
    "    # Create a line plot of loss over training steps\n",
    "    fig = px.line(df, x='step', y='loss', title='Training Loss Over Time')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"The log history does not contain 'loss' or 'step' data.\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "TofHOpaAq0AZ",
    "outputId": "c5d6fb18-0033-4869-c4e5-08f2d4408d6b"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"27168770-abc5-4834-9e2c-0ffd040c691d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"27168770-abc5-4834-9e2c-0ffd040c691d\")) {                    Plotly.newPlot(                        \"27168770-abc5-4834-9e2c-0ffd040c691d\",                        [{\"hovertemplate\":\"step=%{x}\\u003cbr\\u003eloss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,45],\"xaxis\":\"x\",\"y\":[9.8196,9.8923,9.8661,9.7041,9.8018,9.3467,9.2791,8.1,7.6558,6.9757,6.5845,6.4189,6.0962,6.0182,5.6331,5.528,5.3219,5.4286,5.3436,5.2261,4.9912,5.1383,5.0495,4.8711,5.0537,4.8858,4.9225,4.8195,4.9058,4.8268,4.8457,4.9278,4.8869,4.8048,4.8621,4.8341,4.8245,4.7397,4.8723,4.844,4.8317,4.8367,4.9041,4.9088,4.9213,null],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"step\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Training Loss Over Time\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('27168770-abc5-4834-9e2c-0ffd040c691d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pre-enable faster inference if it doesn't need to be done every iteration.\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "results = []\n",
    "TOTAL = len(dataset['test'])\n",
    "\n",
    "for i, example in enumerate(dataset['test'], start=1):\n",
    "    nl = example['NL']\n",
    "    fol = example['FOL']\n",
    "\n",
    "    # Prepare prompt text using the formatted prompt.\n",
    "    prompt_text = malls_prompt.format(\n",
    "        \"Translate the following natural language statements into their corresponding first-order logic representations.\",\n",
    "        nl,\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer([prompt_text], return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
    "    decoded_text = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "    # Find the start of the response section\n",
    "    start_marker = \"### Response:\"\n",
    "    start_idx = decoded_text.find(start_marker)\n",
    "    if start_idx != -1:\n",
    "        response_text = decoded_text[start_idx + len(start_marker):].strip()\n",
    "        # Optionally remove the end-of-text token\n",
    "        end_marker = \"<|end_of_text|>\"\n",
    "        end_idx = response_text.find(end_marker)\n",
    "        if end_idx != -1:\n",
    "            response_text = response_text[:end_idx].strip()\n",
    "    else:\n",
    "        response_text = '<empty>'\n",
    "\n",
    "    results.append({'NL': nl, 'FOL': fol, 'Response': response_text})\n",
    "    print(f\"{i}/{TOTAL} examples processed\")\n",
    "\n",
    "# Create DataFrame once from the accumulated results\n",
    "prediction_result_test = pd.DataFrame(results)\n",
    "prediction_result_test.head()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "YZEPyR-R_d6C",
    "outputId": "c4cb8f02-ac48-4024-d1df-93e89db1a596"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1000 examples processed\n",
      "2/1000 examples processed\n",
      "3/1000 examples processed\n",
      "4/1000 examples processed\n",
      "5/1000 examples processed\n",
      "6/1000 examples processed\n",
      "7/1000 examples processed\n",
      "8/1000 examples processed\n",
      "9/1000 examples processed\n",
      "10/1000 examples processed\n",
      "11/1000 examples processed\n",
      "12/1000 examples processed\n",
      "13/1000 examples processed\n",
      "14/1000 examples processed\n",
      "15/1000 examples processed\n",
      "16/1000 examples processed\n",
      "17/1000 examples processed\n",
      "18/1000 examples processed\n",
      "19/1000 examples processed\n",
      "20/1000 examples processed\n",
      "21/1000 examples processed\n",
      "22/1000 examples processed\n",
      "23/1000 examples processed\n",
      "24/1000 examples processed\n",
      "25/1000 examples processed\n",
      "26/1000 examples processed\n",
      "27/1000 examples processed\n",
      "28/1000 examples processed\n",
      "29/1000 examples processed\n",
      "30/1000 examples processed\n",
      "31/1000 examples processed\n",
      "32/1000 examples processed\n",
      "33/1000 examples processed\n",
      "34/1000 examples processed\n",
      "35/1000 examples processed\n",
      "36/1000 examples processed\n",
      "37/1000 examples processed\n",
      "38/1000 examples processed\n",
      "39/1000 examples processed\n",
      "40/1000 examples processed\n",
      "41/1000 examples processed\n",
      "42/1000 examples processed\n",
      "43/1000 examples processed\n",
      "44/1000 examples processed\n",
      "45/1000 examples processed\n",
      "46/1000 examples processed\n",
      "47/1000 examples processed\n",
      "48/1000 examples processed\n",
      "49/1000 examples processed\n",
      "50/1000 examples processed\n",
      "51/1000 examples processed\n",
      "52/1000 examples processed\n",
      "53/1000 examples processed\n",
      "54/1000 examples processed\n",
      "55/1000 examples processed\n",
      "56/1000 examples processed\n",
      "57/1000 examples processed\n",
      "58/1000 examples processed\n",
      "59/1000 examples processed\n",
      "60/1000 examples processed\n",
      "61/1000 examples processed\n",
      "62/1000 examples processed\n",
      "63/1000 examples processed\n",
      "64/1000 examples processed\n",
      "65/1000 examples processed\n",
      "66/1000 examples processed\n",
      "67/1000 examples processed\n",
      "68/1000 examples processed\n",
      "69/1000 examples processed\n",
      "70/1000 examples processed\n",
      "71/1000 examples processed\n",
      "72/1000 examples processed\n",
      "73/1000 examples processed\n",
      "74/1000 examples processed\n",
      "75/1000 examples processed\n",
      "76/1000 examples processed\n",
      "77/1000 examples processed\n",
      "78/1000 examples processed\n",
      "79/1000 examples processed\n",
      "80/1000 examples processed\n",
      "81/1000 examples processed\n",
      "82/1000 examples processed\n",
      "83/1000 examples processed\n",
      "84/1000 examples processed\n",
      "85/1000 examples processed\n",
      "86/1000 examples processed\n",
      "87/1000 examples processed\n",
      "88/1000 examples processed\n",
      "89/1000 examples processed\n",
      "90/1000 examples processed\n",
      "91/1000 examples processed\n",
      "92/1000 examples processed\n",
      "93/1000 examples processed\n",
      "94/1000 examples processed\n",
      "95/1000 examples processed\n",
      "96/1000 examples processed\n",
      "97/1000 examples processed\n",
      "98/1000 examples processed\n",
      "99/1000 examples processed\n",
      "100/1000 examples processed\n",
      "101/1000 examples processed\n",
      "102/1000 examples processed\n",
      "103/1000 examples processed\n",
      "104/1000 examples processed\n",
      "105/1000 examples processed\n",
      "106/1000 examples processed\n",
      "107/1000 examples processed\n",
      "108/1000 examples processed\n",
      "109/1000 examples processed\n",
      "110/1000 examples processed\n",
      "111/1000 examples processed\n",
      "112/1000 examples processed\n",
      "113/1000 examples processed\n",
      "114/1000 examples processed\n",
      "115/1000 examples processed\n",
      "116/1000 examples processed\n",
      "117/1000 examples processed\n",
      "118/1000 examples processed\n",
      "119/1000 examples processed\n",
      "120/1000 examples processed\n",
      "121/1000 examples processed\n",
      "122/1000 examples processed\n",
      "123/1000 examples processed\n",
      "124/1000 examples processed\n",
      "125/1000 examples processed\n",
      "126/1000 examples processed\n",
      "127/1000 examples processed\n",
      "128/1000 examples processed\n",
      "129/1000 examples processed\n",
      "130/1000 examples processed\n",
      "131/1000 examples processed\n",
      "132/1000 examples processed\n",
      "133/1000 examples processed\n",
      "134/1000 examples processed\n",
      "135/1000 examples processed\n",
      "136/1000 examples processed\n",
      "137/1000 examples processed\n",
      "138/1000 examples processed\n",
      "139/1000 examples processed\n",
      "140/1000 examples processed\n",
      "141/1000 examples processed\n",
      "142/1000 examples processed\n",
      "143/1000 examples processed\n",
      "144/1000 examples processed\n",
      "145/1000 examples processed\n",
      "146/1000 examples processed\n",
      "147/1000 examples processed\n",
      "148/1000 examples processed\n",
      "149/1000 examples processed\n",
      "150/1000 examples processed\n",
      "151/1000 examples processed\n",
      "152/1000 examples processed\n",
      "153/1000 examples processed\n",
      "154/1000 examples processed\n",
      "155/1000 examples processed\n",
      "156/1000 examples processed\n",
      "157/1000 examples processed\n",
      "158/1000 examples processed\n",
      "159/1000 examples processed\n",
      "160/1000 examples processed\n",
      "161/1000 examples processed\n",
      "162/1000 examples processed\n",
      "163/1000 examples processed\n",
      "164/1000 examples processed\n",
      "165/1000 examples processed\n",
      "166/1000 examples processed\n",
      "167/1000 examples processed\n",
      "168/1000 examples processed\n",
      "169/1000 examples processed\n",
      "170/1000 examples processed\n",
      "171/1000 examples processed\n",
      "172/1000 examples processed\n",
      "173/1000 examples processed\n",
      "174/1000 examples processed\n",
      "175/1000 examples processed\n",
      "176/1000 examples processed\n",
      "177/1000 examples processed\n",
      "178/1000 examples processed\n",
      "179/1000 examples processed\n",
      "180/1000 examples processed\n",
      "181/1000 examples processed\n",
      "182/1000 examples processed\n",
      "183/1000 examples processed\n",
      "184/1000 examples processed\n",
      "185/1000 examples processed\n",
      "186/1000 examples processed\n",
      "187/1000 examples processed\n",
      "188/1000 examples processed\n",
      "189/1000 examples processed\n",
      "190/1000 examples processed\n",
      "191/1000 examples processed\n",
      "192/1000 examples processed\n",
      "193/1000 examples processed\n",
      "194/1000 examples processed\n",
      "195/1000 examples processed\n",
      "196/1000 examples processed\n",
      "197/1000 examples processed\n",
      "198/1000 examples processed\n",
      "199/1000 examples processed\n",
      "200/1000 examples processed\n",
      "201/1000 examples processed\n",
      "202/1000 examples processed\n",
      "203/1000 examples processed\n",
      "204/1000 examples processed\n",
      "205/1000 examples processed\n",
      "206/1000 examples processed\n",
      "207/1000 examples processed\n",
      "208/1000 examples processed\n",
      "209/1000 examples processed\n",
      "210/1000 examples processed\n",
      "211/1000 examples processed\n",
      "212/1000 examples processed\n",
      "213/1000 examples processed\n",
      "214/1000 examples processed\n",
      "215/1000 examples processed\n",
      "216/1000 examples processed\n",
      "217/1000 examples processed\n",
      "218/1000 examples processed\n",
      "219/1000 examples processed\n",
      "220/1000 examples processed\n",
      "221/1000 examples processed\n",
      "222/1000 examples processed\n",
      "223/1000 examples processed\n",
      "224/1000 examples processed\n",
      "225/1000 examples processed\n",
      "226/1000 examples processed\n",
      "227/1000 examples processed\n",
      "228/1000 examples processed\n",
      "229/1000 examples processed\n",
      "230/1000 examples processed\n",
      "231/1000 examples processed\n",
      "232/1000 examples processed\n",
      "233/1000 examples processed\n",
      "234/1000 examples processed\n",
      "235/1000 examples processed\n",
      "236/1000 examples processed\n",
      "237/1000 examples processed\n",
      "238/1000 examples processed\n",
      "239/1000 examples processed\n",
      "240/1000 examples processed\n",
      "241/1000 examples processed\n",
      "242/1000 examples processed\n",
      "243/1000 examples processed\n",
      "244/1000 examples processed\n",
      "245/1000 examples processed\n",
      "246/1000 examples processed\n",
      "247/1000 examples processed\n",
      "248/1000 examples processed\n",
      "249/1000 examples processed\n",
      "250/1000 examples processed\n",
      "251/1000 examples processed\n",
      "252/1000 examples processed\n",
      "253/1000 examples processed\n",
      "254/1000 examples processed\n",
      "255/1000 examples processed\n",
      "256/1000 examples processed\n",
      "257/1000 examples processed\n",
      "258/1000 examples processed\n",
      "259/1000 examples processed\n",
      "260/1000 examples processed\n",
      "261/1000 examples processed\n",
      "262/1000 examples processed\n",
      "263/1000 examples processed\n",
      "264/1000 examples processed\n",
      "265/1000 examples processed\n",
      "266/1000 examples processed\n",
      "267/1000 examples processed\n",
      "268/1000 examples processed\n",
      "269/1000 examples processed\n",
      "270/1000 examples processed\n",
      "271/1000 examples processed\n",
      "272/1000 examples processed\n",
      "273/1000 examples processed\n",
      "274/1000 examples processed\n",
      "275/1000 examples processed\n",
      "276/1000 examples processed\n",
      "277/1000 examples processed\n",
      "278/1000 examples processed\n",
      "279/1000 examples processed\n",
      "280/1000 examples processed\n",
      "281/1000 examples processed\n",
      "282/1000 examples processed\n",
      "283/1000 examples processed\n",
      "284/1000 examples processed\n",
      "285/1000 examples processed\n",
      "286/1000 examples processed\n",
      "287/1000 examples processed\n",
      "288/1000 examples processed\n",
      "289/1000 examples processed\n",
      "290/1000 examples processed\n",
      "291/1000 examples processed\n",
      "292/1000 examples processed\n",
      "293/1000 examples processed\n",
      "294/1000 examples processed\n",
      "295/1000 examples processed\n",
      "296/1000 examples processed\n",
      "297/1000 examples processed\n",
      "298/1000 examples processed\n",
      "299/1000 examples processed\n",
      "300/1000 examples processed\n",
      "301/1000 examples processed\n",
      "302/1000 examples processed\n",
      "303/1000 examples processed\n",
      "304/1000 examples processed\n",
      "305/1000 examples processed\n",
      "306/1000 examples processed\n",
      "307/1000 examples processed\n",
      "308/1000 examples processed\n",
      "309/1000 examples processed\n",
      "310/1000 examples processed\n",
      "311/1000 examples processed\n",
      "312/1000 examples processed\n",
      "313/1000 examples processed\n",
      "314/1000 examples processed\n",
      "315/1000 examples processed\n",
      "316/1000 examples processed\n",
      "317/1000 examples processed\n",
      "318/1000 examples processed\n",
      "319/1000 examples processed\n",
      "320/1000 examples processed\n",
      "321/1000 examples processed\n",
      "322/1000 examples processed\n",
      "323/1000 examples processed\n",
      "324/1000 examples processed\n",
      "325/1000 examples processed\n",
      "326/1000 examples processed\n",
      "327/1000 examples processed\n",
      "328/1000 examples processed\n",
      "329/1000 examples processed\n",
      "330/1000 examples processed\n",
      "331/1000 examples processed\n",
      "332/1000 examples processed\n",
      "333/1000 examples processed\n",
      "334/1000 examples processed\n",
      "335/1000 examples processed\n",
      "336/1000 examples processed\n",
      "337/1000 examples processed\n",
      "338/1000 examples processed\n",
      "339/1000 examples processed\n",
      "340/1000 examples processed\n",
      "341/1000 examples processed\n",
      "342/1000 examples processed\n",
      "343/1000 examples processed\n",
      "344/1000 examples processed\n",
      "345/1000 examples processed\n",
      "346/1000 examples processed\n",
      "347/1000 examples processed\n",
      "348/1000 examples processed\n",
      "349/1000 examples processed\n",
      "350/1000 examples processed\n",
      "351/1000 examples processed\n",
      "352/1000 examples processed\n",
      "353/1000 examples processed\n",
      "354/1000 examples processed\n",
      "355/1000 examples processed\n",
      "356/1000 examples processed\n",
      "357/1000 examples processed\n",
      "358/1000 examples processed\n",
      "359/1000 examples processed\n",
      "360/1000 examples processed\n",
      "361/1000 examples processed\n",
      "362/1000 examples processed\n",
      "363/1000 examples processed\n",
      "364/1000 examples processed\n",
      "365/1000 examples processed\n",
      "366/1000 examples processed\n",
      "367/1000 examples processed\n",
      "368/1000 examples processed\n",
      "369/1000 examples processed\n",
      "370/1000 examples processed\n",
      "371/1000 examples processed\n",
      "372/1000 examples processed\n",
      "373/1000 examples processed\n",
      "374/1000 examples processed\n",
      "375/1000 examples processed\n",
      "376/1000 examples processed\n",
      "377/1000 examples processed\n",
      "378/1000 examples processed\n",
      "379/1000 examples processed\n",
      "380/1000 examples processed\n",
      "381/1000 examples processed\n",
      "382/1000 examples processed\n",
      "383/1000 examples processed\n",
      "384/1000 examples processed\n",
      "385/1000 examples processed\n",
      "386/1000 examples processed\n",
      "387/1000 examples processed\n",
      "388/1000 examples processed\n",
      "389/1000 examples processed\n",
      "390/1000 examples processed\n",
      "391/1000 examples processed\n",
      "392/1000 examples processed\n",
      "393/1000 examples processed\n",
      "394/1000 examples processed\n",
      "395/1000 examples processed\n",
      "396/1000 examples processed\n",
      "397/1000 examples processed\n",
      "398/1000 examples processed\n",
      "399/1000 examples processed\n",
      "400/1000 examples processed\n",
      "401/1000 examples processed\n",
      "402/1000 examples processed\n",
      "403/1000 examples processed\n",
      "404/1000 examples processed\n",
      "405/1000 examples processed\n",
      "406/1000 examples processed\n",
      "407/1000 examples processed\n",
      "408/1000 examples processed\n",
      "409/1000 examples processed\n",
      "410/1000 examples processed\n",
      "411/1000 examples processed\n",
      "412/1000 examples processed\n",
      "413/1000 examples processed\n",
      "414/1000 examples processed\n",
      "415/1000 examples processed\n",
      "416/1000 examples processed\n",
      "417/1000 examples processed\n",
      "418/1000 examples processed\n",
      "419/1000 examples processed\n",
      "420/1000 examples processed\n",
      "421/1000 examples processed\n",
      "422/1000 examples processed\n",
      "423/1000 examples processed\n",
      "424/1000 examples processed\n",
      "425/1000 examples processed\n",
      "426/1000 examples processed\n",
      "427/1000 examples processed\n",
      "428/1000 examples processed\n",
      "429/1000 examples processed\n",
      "430/1000 examples processed\n",
      "431/1000 examples processed\n",
      "432/1000 examples processed\n",
      "433/1000 examples processed\n",
      "434/1000 examples processed\n",
      "435/1000 examples processed\n",
      "436/1000 examples processed\n",
      "437/1000 examples processed\n",
      "438/1000 examples processed\n",
      "439/1000 examples processed\n",
      "440/1000 examples processed\n",
      "441/1000 examples processed\n",
      "442/1000 examples processed\n",
      "443/1000 examples processed\n",
      "444/1000 examples processed\n",
      "445/1000 examples processed\n",
      "446/1000 examples processed\n",
      "447/1000 examples processed\n",
      "448/1000 examples processed\n",
      "449/1000 examples processed\n",
      "450/1000 examples processed\n",
      "451/1000 examples processed\n",
      "452/1000 examples processed\n",
      "453/1000 examples processed\n",
      "454/1000 examples processed\n",
      "455/1000 examples processed\n",
      "456/1000 examples processed\n",
      "457/1000 examples processed\n",
      "458/1000 examples processed\n",
      "459/1000 examples processed\n",
      "460/1000 examples processed\n",
      "461/1000 examples processed\n",
      "462/1000 examples processed\n",
      "463/1000 examples processed\n",
      "464/1000 examples processed\n",
      "465/1000 examples processed\n",
      "466/1000 examples processed\n",
      "467/1000 examples processed\n",
      "468/1000 examples processed\n",
      "469/1000 examples processed\n",
      "470/1000 examples processed\n",
      "471/1000 examples processed\n",
      "472/1000 examples processed\n",
      "473/1000 examples processed\n",
      "474/1000 examples processed\n",
      "475/1000 examples processed\n",
      "476/1000 examples processed\n",
      "477/1000 examples processed\n",
      "478/1000 examples processed\n",
      "479/1000 examples processed\n",
      "480/1000 examples processed\n",
      "481/1000 examples processed\n",
      "482/1000 examples processed\n",
      "483/1000 examples processed\n",
      "484/1000 examples processed\n",
      "485/1000 examples processed\n",
      "486/1000 examples processed\n",
      "487/1000 examples processed\n",
      "488/1000 examples processed\n",
      "489/1000 examples processed\n",
      "490/1000 examples processed\n",
      "491/1000 examples processed\n",
      "492/1000 examples processed\n",
      "493/1000 examples processed\n",
      "494/1000 examples processed\n",
      "495/1000 examples processed\n",
      "496/1000 examples processed\n",
      "497/1000 examples processed\n",
      "498/1000 examples processed\n",
      "499/1000 examples processed\n",
      "500/1000 examples processed\n",
      "501/1000 examples processed\n",
      "502/1000 examples processed\n",
      "503/1000 examples processed\n",
      "504/1000 examples processed\n",
      "505/1000 examples processed\n",
      "506/1000 examples processed\n",
      "507/1000 examples processed\n",
      "508/1000 examples processed\n",
      "509/1000 examples processed\n",
      "510/1000 examples processed\n",
      "511/1000 examples processed\n",
      "512/1000 examples processed\n",
      "513/1000 examples processed\n",
      "514/1000 examples processed\n",
      "515/1000 examples processed\n",
      "516/1000 examples processed\n",
      "517/1000 examples processed\n",
      "518/1000 examples processed\n",
      "519/1000 examples processed\n",
      "520/1000 examples processed\n",
      "521/1000 examples processed\n",
      "522/1000 examples processed\n",
      "523/1000 examples processed\n",
      "524/1000 examples processed\n",
      "525/1000 examples processed\n",
      "526/1000 examples processed\n",
      "527/1000 examples processed\n",
      "528/1000 examples processed\n",
      "529/1000 examples processed\n",
      "530/1000 examples processed\n",
      "531/1000 examples processed\n",
      "532/1000 examples processed\n",
      "533/1000 examples processed\n",
      "534/1000 examples processed\n",
      "535/1000 examples processed\n",
      "536/1000 examples processed\n",
      "537/1000 examples processed\n",
      "538/1000 examples processed\n",
      "539/1000 examples processed\n",
      "540/1000 examples processed\n",
      "541/1000 examples processed\n",
      "542/1000 examples processed\n",
      "543/1000 examples processed\n",
      "544/1000 examples processed\n",
      "545/1000 examples processed\n",
      "546/1000 examples processed\n",
      "547/1000 examples processed\n",
      "548/1000 examples processed\n",
      "549/1000 examples processed\n",
      "550/1000 examples processed\n",
      "551/1000 examples processed\n",
      "552/1000 examples processed\n",
      "553/1000 examples processed\n",
      "554/1000 examples processed\n",
      "555/1000 examples processed\n",
      "556/1000 examples processed\n",
      "557/1000 examples processed\n",
      "558/1000 examples processed\n",
      "559/1000 examples processed\n",
      "560/1000 examples processed\n",
      "561/1000 examples processed\n",
      "562/1000 examples processed\n",
      "563/1000 examples processed\n",
      "564/1000 examples processed\n",
      "565/1000 examples processed\n",
      "566/1000 examples processed\n",
      "567/1000 examples processed\n",
      "568/1000 examples processed\n",
      "569/1000 examples processed\n",
      "570/1000 examples processed\n",
      "571/1000 examples processed\n",
      "572/1000 examples processed\n",
      "573/1000 examples processed\n",
      "574/1000 examples processed\n",
      "575/1000 examples processed\n",
      "576/1000 examples processed\n",
      "577/1000 examples processed\n",
      "578/1000 examples processed\n",
      "579/1000 examples processed\n",
      "580/1000 examples processed\n",
      "581/1000 examples processed\n",
      "582/1000 examples processed\n",
      "583/1000 examples processed\n",
      "584/1000 examples processed\n",
      "585/1000 examples processed\n",
      "586/1000 examples processed\n",
      "587/1000 examples processed\n",
      "588/1000 examples processed\n",
      "589/1000 examples processed\n",
      "590/1000 examples processed\n",
      "591/1000 examples processed\n",
      "592/1000 examples processed\n",
      "593/1000 examples processed\n",
      "594/1000 examples processed\n",
      "595/1000 examples processed\n",
      "596/1000 examples processed\n",
      "597/1000 examples processed\n",
      "598/1000 examples processed\n",
      "599/1000 examples processed\n",
      "600/1000 examples processed\n",
      "601/1000 examples processed\n",
      "602/1000 examples processed\n",
      "603/1000 examples processed\n",
      "604/1000 examples processed\n",
      "605/1000 examples processed\n",
      "606/1000 examples processed\n",
      "607/1000 examples processed\n",
      "608/1000 examples processed\n",
      "609/1000 examples processed\n",
      "610/1000 examples processed\n",
      "611/1000 examples processed\n",
      "612/1000 examples processed\n",
      "613/1000 examples processed\n",
      "614/1000 examples processed\n",
      "615/1000 examples processed\n",
      "616/1000 examples processed\n",
      "617/1000 examples processed\n",
      "618/1000 examples processed\n",
      "619/1000 examples processed\n",
      "620/1000 examples processed\n",
      "621/1000 examples processed\n",
      "622/1000 examples processed\n",
      "623/1000 examples processed\n",
      "624/1000 examples processed\n",
      "625/1000 examples processed\n",
      "626/1000 examples processed\n",
      "627/1000 examples processed\n",
      "628/1000 examples processed\n",
      "629/1000 examples processed\n",
      "630/1000 examples processed\n",
      "631/1000 examples processed\n",
      "632/1000 examples processed\n",
      "633/1000 examples processed\n",
      "634/1000 examples processed\n",
      "635/1000 examples processed\n",
      "636/1000 examples processed\n",
      "637/1000 examples processed\n",
      "638/1000 examples processed\n",
      "639/1000 examples processed\n",
      "640/1000 examples processed\n",
      "641/1000 examples processed\n",
      "642/1000 examples processed\n",
      "643/1000 examples processed\n",
      "644/1000 examples processed\n",
      "645/1000 examples processed\n",
      "646/1000 examples processed\n",
      "647/1000 examples processed\n",
      "648/1000 examples processed\n",
      "649/1000 examples processed\n",
      "650/1000 examples processed\n",
      "651/1000 examples processed\n",
      "652/1000 examples processed\n",
      "653/1000 examples processed\n",
      "654/1000 examples processed\n",
      "655/1000 examples processed\n",
      "656/1000 examples processed\n",
      "657/1000 examples processed\n",
      "658/1000 examples processed\n",
      "659/1000 examples processed\n",
      "660/1000 examples processed\n",
      "661/1000 examples processed\n",
      "662/1000 examples processed\n",
      "663/1000 examples processed\n",
      "664/1000 examples processed\n",
      "665/1000 examples processed\n",
      "666/1000 examples processed\n",
      "667/1000 examples processed\n",
      "668/1000 examples processed\n",
      "669/1000 examples processed\n",
      "670/1000 examples processed\n",
      "671/1000 examples processed\n",
      "672/1000 examples processed\n",
      "673/1000 examples processed\n",
      "674/1000 examples processed\n",
      "675/1000 examples processed\n",
      "676/1000 examples processed\n",
      "677/1000 examples processed\n",
      "678/1000 examples processed\n",
      "679/1000 examples processed\n",
      "680/1000 examples processed\n",
      "681/1000 examples processed\n",
      "682/1000 examples processed\n",
      "683/1000 examples processed\n",
      "684/1000 examples processed\n",
      "685/1000 examples processed\n",
      "686/1000 examples processed\n",
      "687/1000 examples processed\n",
      "688/1000 examples processed\n",
      "689/1000 examples processed\n",
      "690/1000 examples processed\n",
      "691/1000 examples processed\n",
      "692/1000 examples processed\n",
      "693/1000 examples processed\n",
      "694/1000 examples processed\n",
      "695/1000 examples processed\n",
      "696/1000 examples processed\n",
      "697/1000 examples processed\n",
      "698/1000 examples processed\n",
      "699/1000 examples processed\n",
      "700/1000 examples processed\n",
      "701/1000 examples processed\n",
      "702/1000 examples processed\n",
      "703/1000 examples processed\n",
      "704/1000 examples processed\n",
      "705/1000 examples processed\n",
      "706/1000 examples processed\n",
      "707/1000 examples processed\n",
      "708/1000 examples processed\n",
      "709/1000 examples processed\n",
      "710/1000 examples processed\n",
      "711/1000 examples processed\n",
      "712/1000 examples processed\n",
      "713/1000 examples processed\n",
      "714/1000 examples processed\n",
      "715/1000 examples processed\n",
      "716/1000 examples processed\n",
      "717/1000 examples processed\n",
      "718/1000 examples processed\n",
      "719/1000 examples processed\n",
      "720/1000 examples processed\n",
      "721/1000 examples processed\n",
      "722/1000 examples processed\n",
      "723/1000 examples processed\n",
      "724/1000 examples processed\n",
      "725/1000 examples processed\n",
      "726/1000 examples processed\n",
      "727/1000 examples processed\n",
      "728/1000 examples processed\n",
      "729/1000 examples processed\n",
      "730/1000 examples processed\n",
      "731/1000 examples processed\n",
      "732/1000 examples processed\n",
      "733/1000 examples processed\n",
      "734/1000 examples processed\n",
      "735/1000 examples processed\n",
      "736/1000 examples processed\n",
      "737/1000 examples processed\n",
      "738/1000 examples processed\n",
      "739/1000 examples processed\n",
      "740/1000 examples processed\n",
      "741/1000 examples processed\n",
      "742/1000 examples processed\n",
      "743/1000 examples processed\n",
      "744/1000 examples processed\n",
      "745/1000 examples processed\n",
      "746/1000 examples processed\n",
      "747/1000 examples processed\n",
      "748/1000 examples processed\n",
      "749/1000 examples processed\n",
      "750/1000 examples processed\n",
      "751/1000 examples processed\n",
      "752/1000 examples processed\n",
      "753/1000 examples processed\n",
      "754/1000 examples processed\n",
      "755/1000 examples processed\n",
      "756/1000 examples processed\n",
      "757/1000 examples processed\n",
      "758/1000 examples processed\n",
      "759/1000 examples processed\n",
      "760/1000 examples processed\n",
      "761/1000 examples processed\n",
      "762/1000 examples processed\n",
      "763/1000 examples processed\n",
      "764/1000 examples processed\n",
      "765/1000 examples processed\n",
      "766/1000 examples processed\n",
      "767/1000 examples processed\n",
      "768/1000 examples processed\n",
      "769/1000 examples processed\n",
      "770/1000 examples processed\n",
      "771/1000 examples processed\n",
      "772/1000 examples processed\n",
      "773/1000 examples processed\n",
      "774/1000 examples processed\n",
      "775/1000 examples processed\n",
      "776/1000 examples processed\n",
      "777/1000 examples processed\n",
      "778/1000 examples processed\n",
      "779/1000 examples processed\n",
      "780/1000 examples processed\n",
      "781/1000 examples processed\n",
      "782/1000 examples processed\n",
      "783/1000 examples processed\n",
      "784/1000 examples processed\n",
      "785/1000 examples processed\n",
      "786/1000 examples processed\n",
      "787/1000 examples processed\n",
      "788/1000 examples processed\n",
      "789/1000 examples processed\n",
      "790/1000 examples processed\n",
      "791/1000 examples processed\n",
      "792/1000 examples processed\n",
      "793/1000 examples processed\n",
      "794/1000 examples processed\n",
      "795/1000 examples processed\n",
      "796/1000 examples processed\n",
      "797/1000 examples processed\n",
      "798/1000 examples processed\n",
      "799/1000 examples processed\n",
      "800/1000 examples processed\n",
      "801/1000 examples processed\n",
      "802/1000 examples processed\n",
      "803/1000 examples processed\n",
      "804/1000 examples processed\n",
      "805/1000 examples processed\n",
      "806/1000 examples processed\n",
      "807/1000 examples processed\n",
      "808/1000 examples processed\n",
      "809/1000 examples processed\n",
      "810/1000 examples processed\n",
      "811/1000 examples processed\n",
      "812/1000 examples processed\n",
      "813/1000 examples processed\n",
      "814/1000 examples processed\n",
      "815/1000 examples processed\n",
      "816/1000 examples processed\n",
      "817/1000 examples processed\n",
      "818/1000 examples processed\n",
      "819/1000 examples processed\n",
      "820/1000 examples processed\n",
      "821/1000 examples processed\n",
      "822/1000 examples processed\n",
      "823/1000 examples processed\n",
      "824/1000 examples processed\n",
      "825/1000 examples processed\n",
      "826/1000 examples processed\n",
      "827/1000 examples processed\n",
      "828/1000 examples processed\n",
      "829/1000 examples processed\n",
      "830/1000 examples processed\n",
      "831/1000 examples processed\n",
      "832/1000 examples processed\n",
      "833/1000 examples processed\n",
      "834/1000 examples processed\n",
      "835/1000 examples processed\n",
      "836/1000 examples processed\n",
      "837/1000 examples processed\n",
      "838/1000 examples processed\n",
      "839/1000 examples processed\n",
      "840/1000 examples processed\n",
      "841/1000 examples processed\n",
      "842/1000 examples processed\n",
      "843/1000 examples processed\n",
      "844/1000 examples processed\n",
      "845/1000 examples processed\n",
      "846/1000 examples processed\n",
      "847/1000 examples processed\n",
      "848/1000 examples processed\n",
      "849/1000 examples processed\n",
      "850/1000 examples processed\n",
      "851/1000 examples processed\n",
      "852/1000 examples processed\n",
      "853/1000 examples processed\n",
      "854/1000 examples processed\n",
      "855/1000 examples processed\n",
      "856/1000 examples processed\n",
      "857/1000 examples processed\n",
      "858/1000 examples processed\n",
      "859/1000 examples processed\n",
      "860/1000 examples processed\n",
      "861/1000 examples processed\n",
      "862/1000 examples processed\n",
      "863/1000 examples processed\n",
      "864/1000 examples processed\n",
      "865/1000 examples processed\n",
      "866/1000 examples processed\n",
      "867/1000 examples processed\n",
      "868/1000 examples processed\n",
      "869/1000 examples processed\n",
      "870/1000 examples processed\n",
      "871/1000 examples processed\n",
      "872/1000 examples processed\n",
      "873/1000 examples processed\n",
      "874/1000 examples processed\n",
      "875/1000 examples processed\n",
      "876/1000 examples processed\n",
      "877/1000 examples processed\n",
      "878/1000 examples processed\n",
      "879/1000 examples processed\n",
      "880/1000 examples processed\n",
      "881/1000 examples processed\n",
      "882/1000 examples processed\n",
      "883/1000 examples processed\n",
      "884/1000 examples processed\n",
      "885/1000 examples processed\n",
      "886/1000 examples processed\n",
      "887/1000 examples processed\n",
      "888/1000 examples processed\n",
      "889/1000 examples processed\n",
      "890/1000 examples processed\n",
      "891/1000 examples processed\n",
      "892/1000 examples processed\n",
      "893/1000 examples processed\n",
      "894/1000 examples processed\n",
      "895/1000 examples processed\n",
      "896/1000 examples processed\n",
      "897/1000 examples processed\n",
      "898/1000 examples processed\n",
      "899/1000 examples processed\n",
      "900/1000 examples processed\n",
      "901/1000 examples processed\n",
      "902/1000 examples processed\n",
      "903/1000 examples processed\n",
      "904/1000 examples processed\n",
      "905/1000 examples processed\n",
      "906/1000 examples processed\n",
      "907/1000 examples processed\n",
      "908/1000 examples processed\n",
      "909/1000 examples processed\n",
      "910/1000 examples processed\n",
      "911/1000 examples processed\n",
      "912/1000 examples processed\n",
      "913/1000 examples processed\n",
      "914/1000 examples processed\n",
      "915/1000 examples processed\n",
      "916/1000 examples processed\n",
      "917/1000 examples processed\n",
      "918/1000 examples processed\n",
      "919/1000 examples processed\n",
      "920/1000 examples processed\n",
      "921/1000 examples processed\n",
      "922/1000 examples processed\n",
      "923/1000 examples processed\n",
      "924/1000 examples processed\n",
      "925/1000 examples processed\n",
      "926/1000 examples processed\n",
      "927/1000 examples processed\n",
      "928/1000 examples processed\n",
      "929/1000 examples processed\n",
      "930/1000 examples processed\n",
      "931/1000 examples processed\n",
      "932/1000 examples processed\n",
      "933/1000 examples processed\n",
      "934/1000 examples processed\n",
      "935/1000 examples processed\n",
      "936/1000 examples processed\n",
      "937/1000 examples processed\n",
      "938/1000 examples processed\n",
      "939/1000 examples processed\n",
      "940/1000 examples processed\n",
      "941/1000 examples processed\n",
      "942/1000 examples processed\n",
      "943/1000 examples processed\n",
      "944/1000 examples processed\n",
      "945/1000 examples processed\n",
      "946/1000 examples processed\n",
      "947/1000 examples processed\n",
      "948/1000 examples processed\n",
      "949/1000 examples processed\n",
      "950/1000 examples processed\n",
      "951/1000 examples processed\n",
      "952/1000 examples processed\n",
      "953/1000 examples processed\n",
      "954/1000 examples processed\n",
      "955/1000 examples processed\n",
      "956/1000 examples processed\n",
      "957/1000 examples processed\n",
      "958/1000 examples processed\n",
      "959/1000 examples processed\n",
      "960/1000 examples processed\n",
      "961/1000 examples processed\n",
      "962/1000 examples processed\n",
      "963/1000 examples processed\n",
      "964/1000 examples processed\n",
      "965/1000 examples processed\n",
      "966/1000 examples processed\n",
      "967/1000 examples processed\n",
      "968/1000 examples processed\n",
      "969/1000 examples processed\n",
      "970/1000 examples processed\n",
      "971/1000 examples processed\n",
      "972/1000 examples processed\n",
      "973/1000 examples processed\n",
      "974/1000 examples processed\n",
      "975/1000 examples processed\n",
      "976/1000 examples processed\n",
      "977/1000 examples processed\n",
      "978/1000 examples processed\n",
      "979/1000 examples processed\n",
      "980/1000 examples processed\n",
      "981/1000 examples processed\n",
      "982/1000 examples processed\n",
      "983/1000 examples processed\n",
      "984/1000 examples processed\n",
      "985/1000 examples processed\n",
      "986/1000 examples processed\n",
      "987/1000 examples processed\n",
      "988/1000 examples processed\n",
      "989/1000 examples processed\n",
      "990/1000 examples processed\n",
      "991/1000 examples processed\n",
      "992/1000 examples processed\n",
      "993/1000 examples processed\n",
      "994/1000 examples processed\n",
      "995/1000 examples processed\n",
      "996/1000 examples processed\n",
      "997/1000 examples processed\n",
      "998/1000 examples processed\n",
      "999/1000 examples processed\n",
      "1000/1000 examples processed\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  NL  \\\n",
       "0  A vacation is relaxing if it includes beautifu...   \n",
       "1  A gemstone can be a diamond, a ruby, or an eme...   \n",
       "2  People who speak more than one language are bi...   \n",
       "3  An organization is non-profit if it has a char...   \n",
       "4  A flower is characterized as a monocot if it h...   \n",
       "\n",
       "                                                 FOL  \\\n",
       "0  âˆ€x (Vacation(x) âˆ§ Relaxing(x) â†’ (BeautifulScen...   \n",
       "1  âˆ€x (Gemstone(x) â†’ ((Diamond(x) âˆ§ Â¬(Ruby(x) âˆ¨ E...   \n",
       "2  âˆ€x (SpeakMultipleLanguages(x) â†’ (Bilingual(x) ...   \n",
       "3  âˆ€x (Organization(x) âˆ§ CharitableMission(x) âˆ§ Â¬...   \n",
       "4  âˆ€x (Flower(x) âˆ§ SingleCotyledon(x) âˆ§ ParallelV...   \n",
       "\n",
       "                                            Response  \n",
       "0  âˆ€x (Vacation(x) âˆ§ IncludesBeautifulScenery(x) ...  \n",
       "1  âˆ€x (Gemstone(x) â†’ (Diamond(x) âˆ¨ Ruby(x) âˆ¨ Emer...  \n",
       "2  âˆ€x (Person(x) âˆ§ SpeaksMultipleLanguages(x) â†’ (...  \n",
       "3  âˆ€x (Organization(x) âˆ§ CharitableMission(x) âˆ§ N...  \n",
       "4  âˆ€x (Flower(x) âˆ§ Monocot(x) â†” (SingleCotyledon(...  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-3ced9714-8092-433d-95aa-512af03d4b8e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NL</th>\n",
       "      <th>FOL</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A vacation is relaxing if it includes beautifu...</td>\n",
       "      <td>âˆ€x (Vacation(x) âˆ§ Relaxing(x) â†’ (BeautifulScen...</td>\n",
       "      <td>âˆ€x (Vacation(x) âˆ§ IncludesBeautifulScenery(x) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A gemstone can be a diamond, a ruby, or an eme...</td>\n",
       "      <td>âˆ€x (Gemstone(x) â†’ ((Diamond(x) âˆ§ Â¬(Ruby(x) âˆ¨ E...</td>\n",
       "      <td>âˆ€x (Gemstone(x) â†’ (Diamond(x) âˆ¨ Ruby(x) âˆ¨ Emer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People who speak more than one language are bi...</td>\n",
       "      <td>âˆ€x (SpeakMultipleLanguages(x) â†’ (Bilingual(x) ...</td>\n",
       "      <td>âˆ€x (Person(x) âˆ§ SpeaksMultipleLanguages(x) â†’ (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An organization is non-profit if it has a char...</td>\n",
       "      <td>âˆ€x (Organization(x) âˆ§ CharitableMission(x) âˆ§ Â¬...</td>\n",
       "      <td>âˆ€x (Organization(x) âˆ§ CharitableMission(x) âˆ§ N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A flower is characterized as a monocot if it h...</td>\n",
       "      <td>âˆ€x (Flower(x) âˆ§ SingleCotyledon(x) âˆ§ ParallelV...</td>\n",
       "      <td>âˆ€x (Flower(x) âˆ§ Monocot(x) â†” (SingleCotyledon(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ced9714-8092-433d-95aa-512af03d4b8e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3ced9714-8092-433d-95aa-512af03d4b8e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3ced9714-8092-433d-95aa-512af03d4b8e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-5798d765-3e6e-48e6-bf02-348a4add19b2\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5798d765-3e6e-48e6-bf02-348a4add19b2')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-5798d765-3e6e-48e6-bf02-348a4add19b2 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "prediction_result_test",
       "summary": "{\n  \"name\": \"prediction_result_test\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"NL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"A building x is a museum if it is dedicated to the collection, preservation, interpretation, and display of objects of artistic, cultural, or scientific importance.\",\n          \"A vaccine provides immunity to a disease if it triggers an immune response and generates specific antibodies.\",\n          \"A city is considered a metropolis if it has a large population and significant economic, cultural, and political influence.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FOL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 998,\n        \"samples\": [\n          \"\\u2200x \\u2200y \\u2200z (Medicine(x) \\u2227 Disease(y) \\u2227 Patient(z) \\u2227 TargetsCausativeAgent(x, y) \\u2227 ProducesPositiveOutcome(x, z) \\u2192 EffectiveAgainstDiseaseForPatient(x, y, z))\",\n          \"\\u2200x (Beverage(x) \\u2227 (Carbonated(x) \\u2228 Caffeinated(x)) \\u2192 Refreshing(x))\",\n          \"\\u2200x (Restaurant(x) \\u2192 (ServesVeganFood(x) \\u2228 ServesVegetarianFood(x)) \\u2227 \\u00ac(\\u00acServesVeganFood(x) \\u2227 \\u00acServesVegetarianFood(x)))\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 998,\n        \"samples\": [\n          \"\\u2200x\\u2200y\\u2200z (Medicine(x) \\u2227 Disease(y) \\u2227 Patient(z) \\u2227 TargetsCausativeAgent(x, y) \\u2227 ProducesPositiveOutcomeInHealthCondition(x, z)) \\u2192 EffectiveAgainstDisease(x, y, z)\",\n          \"\\u2200x (Beverage(x) \\u2227 (Carbonated(x) \\u2228 Caffeinated(x)) \\u2192 Refreshing(x))\",\n          \"\\u2200x (Restaurant(x) \\u2192 (VeganFood(x) \\u2228 VegetarianFood(x) \\u2228 (VeganFood(x) \\u2227 VegetarianFood(x))) \\u2227 ~(NeitherFood(x)))\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# prediction_result_test.to_csv('prediction_result_test.csv', index=False)"
   ],
   "metadata": {
    "id": "pTaPs8VoEhXc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prediction_result_test.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bpvS7FwaSBqc",
    "outputId": "b3799d85-d941-48ec-90e8-e6c75c792b40"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  NL  \\\n",
       "0  A vacation is relaxing if it includes beautifu...   \n",
       "1  A gemstone can be a diamond, a ruby, or an eme...   \n",
       "2  People who speak more than one language are bi...   \n",
       "3  An organization is non-profit if it has a char...   \n",
       "4  A flower is characterized as a monocot if it h...   \n",
       "\n",
       "                                                 FOL  \\\n",
       "0  âˆ€x (Vacation(x) âˆ§ Relaxing(x) â†’ (BeautifulScen...   \n",
       "1  âˆ€x (Gemstone(x) â†’ ((Diamond(x) âˆ§ Â¬(Ruby(x) âˆ¨ E...   \n",
       "2  âˆ€x (SpeakMultipleLanguages(x) â†’ (Bilingual(x) ...   \n",
       "3  âˆ€x (Organization(x) âˆ§ CharitableMission(x) âˆ§ Â¬...   \n",
       "4  âˆ€x (Flower(x) âˆ§ SingleCotyledon(x) âˆ§ ParallelV...   \n",
       "\n",
       "                                            Response  \n",
       "0  âˆ€x (Vacation(x) âˆ§ IncludesBeautifulScenery(x) ...  \n",
       "1  âˆ€x (Gemstone(x) â†’ (Diamond(x) âˆ¨ Ruby(x) âˆ¨ Emer...  \n",
       "2  âˆ€x (Person(x) âˆ§ SpeaksMultipleLanguages(x) â†’ (...  \n",
       "3  âˆ€x (Organization(x) âˆ§ CharitableMission(x) âˆ§ N...  \n",
       "4  âˆ€x (Flower(x) âˆ§ Monocot(x) â†” (SingleCotyledon(...  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-a07c6f67-bcff-41b8-9ba8-10fe6f189fe5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NL</th>\n",
       "      <th>FOL</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A vacation is relaxing if it includes beautifu...</td>\n",
       "      <td>âˆ€x (Vacation(x) âˆ§ Relaxing(x) â†’ (BeautifulScen...</td>\n",
       "      <td>âˆ€x (Vacation(x) âˆ§ IncludesBeautifulScenery(x) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A gemstone can be a diamond, a ruby, or an eme...</td>\n",
       "      <td>âˆ€x (Gemstone(x) â†’ ((Diamond(x) âˆ§ Â¬(Ruby(x) âˆ¨ E...</td>\n",
       "      <td>âˆ€x (Gemstone(x) â†’ (Diamond(x) âˆ¨ Ruby(x) âˆ¨ Emer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People who speak more than one language are bi...</td>\n",
       "      <td>âˆ€x (SpeakMultipleLanguages(x) â†’ (Bilingual(x) ...</td>\n",
       "      <td>âˆ€x (Person(x) âˆ§ SpeaksMultipleLanguages(x) â†’ (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An organization is non-profit if it has a char...</td>\n",
       "      <td>âˆ€x (Organization(x) âˆ§ CharitableMission(x) âˆ§ Â¬...</td>\n",
       "      <td>âˆ€x (Organization(x) âˆ§ CharitableMission(x) âˆ§ N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A flower is characterized as a monocot if it h...</td>\n",
       "      <td>âˆ€x (Flower(x) âˆ§ SingleCotyledon(x) âˆ§ ParallelV...</td>\n",
       "      <td>âˆ€x (Flower(x) âˆ§ Monocot(x) â†” (SingleCotyledon(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a07c6f67-bcff-41b8-9ba8-10fe6f189fe5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a07c6f67-bcff-41b8-9ba8-10fe6f189fe5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a07c6f67-bcff-41b8-9ba8-10fe6f189fe5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-9363b936-b42d-44eb-bd35-59633d7aa916\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9363b936-b42d-44eb-bd35-59633d7aa916')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-9363b936-b42d-44eb-bd35-59633d7aa916 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "prediction_result_test",
       "summary": "{\n  \"name\": \"prediction_result_test\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"NL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"A building x is a museum if it is dedicated to the collection, preservation, interpretation, and display of objects of artistic, cultural, or scientific importance.\",\n          \"A vaccine provides immunity to a disease if it triggers an immune response and generates specific antibodies.\",\n          \"A city is considered a metropolis if it has a large population and significant economic, cultural, and political influence.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FOL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 998,\n        \"samples\": [\n          \"\\u2200x \\u2200y \\u2200z (Medicine(x) \\u2227 Disease(y) \\u2227 Patient(z) \\u2227 TargetsCausativeAgent(x, y) \\u2227 ProducesPositiveOutcome(x, z) \\u2192 EffectiveAgainstDiseaseForPatient(x, y, z))\",\n          \"\\u2200x (Beverage(x) \\u2227 (Carbonated(x) \\u2228 Caffeinated(x)) \\u2192 Refreshing(x))\",\n          \"\\u2200x (Restaurant(x) \\u2192 (ServesVeganFood(x) \\u2228 ServesVegetarianFood(x)) \\u2227 \\u00ac(\\u00acServesVeganFood(x) \\u2227 \\u00acServesVegetarianFood(x)))\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 998,\n        \"samples\": [\n          \"\\u2200x\\u2200y\\u2200z (Medicine(x) \\u2227 Disease(y) \\u2227 Patient(z) \\u2227 TargetsCausativeAgent(x, y) \\u2227 ProducesPositiveOutcomeInHealthCondition(x, z)) \\u2192 EffectiveAgainstDisease(x, y, z)\",\n          \"\\u2200x (Beverage(x) \\u2227 (Carbonated(x) \\u2228 Caffeinated(x)) \\u2192 Refreshing(x))\",\n          \"\\u2200x (Restaurant(x) \\u2192 (VeganFood(x) \\u2228 VegetarianFood(x) \\u2228 (VeganFood(x) \\u2227 VegetarianFood(x))) \\u2227 ~(NeitherFood(x)))\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pCqnaKmlO1U9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "af4b94e9-4707-44cb-9e53-befb22ad94b2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "492.2389 seconds used for training.\n",
      "8.2 minutes used for training.\n",
      "Peak reserved memory = 7.281 GB.\n",
      "Peak reserved memory for training = 0.31 GB.\n",
      "Peak reserved memory % of max memory = 49.393 %.\n",
      "Peak reserved memory for training % of max memory = 2.103 %.\n"
     ]
    }
   ],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SAVE THE MODEL"
   ],
   "metadata": {
    "id": "9LWOW423G_NZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"lora_model\") # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLfqw7oCHAzR",
    "outputId": "c82b7eb3-a9f0-46e6-a130-92aadda95f26"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DEMO"
   ],
   "metadata": {
    "id": "eB3mBY31PU1C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    malls_prompt.format(\n",
    "        \"Translate the following natural language statements into their corresponding first-order logic representations\", # instruction\n",
    "        \"Some dog is a pet\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PX2AVjyGHBn0",
    "outputId": "fe732d7e-c887-4409-ff76-7d865f736779"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Translate the following natural language statements into their corresponding first-order logic representations\n",
      "\n",
      "### Input:\n",
      "Some dog is a pet\n",
      "\n",
      "### Response:\n",
      "âˆƒx (Dog(x) âˆ§ Pet(x))<|end_of_text|>\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}